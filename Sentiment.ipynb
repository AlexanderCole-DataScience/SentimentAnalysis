{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj42CnGmb7V7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/LinkedInReviews.xlsx')"
      ],
      "metadata": {
        "id": "rcvgd2JqcLpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkz2WCvUcodw",
        "outputId": "24dbaa95-4d7e-41ce-9c19-605374508389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Review Sentiment\n",
            "0   What the $#*!. I tried to get into my LinkedIn...  negative\n",
            "1   Unfortunately if you aren't on Linkedin you wi...  negative\n",
            "2   Very bad, they rip you off with very expensive...  negative\n",
            "3   I don't really use LinkedIn except an occasion...  negative\n",
            "4   I had a long term account that was hacked into...  negative\n",
            "..                                                ...       ...\n",
            "95  I signed up with LinkedIn a while ago and deci...  negative\n",
            "96  I spend $6,000 a year on a single LinkedIn Rec...  negative\n",
            "97  I created an account and was then asked to ver...  negative\n",
            "98  I have tried using LinkedIn over 50 times and ...  negative\n",
            "99  My account was restricted for some reason. I c...  negative\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "#DataFrame 'df' with columns 'Review' and 'Sentiment'\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Sentiment'], test_size=0.5, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "predictions = model.predict(X_test_vectorized)\n",
        "\n",
        "#Converts 'y' variable to 1's and 0's\n",
        "y_test = [1 if label == \"positive\" else 0 for label in y_test]\n",
        "predictions = [1 if label == \"positive\" else 0 for label in predictions]\n",
        "\n",
        "confusion_matr = confusion_matrix(y_test, predictions)\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, predictions))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, predictions))\n",
        "print(\"F1 Score:\", metrics.f1_score(y_test, predictions))\n",
        "print(confusion_matr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OStO4msOcwT9",
        "outputId": "0da7dd08-2fef-4ae9-e517-71c04c746443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94\n",
            "Precision: 0.9130434782608695\n",
            "Recall: 0.9545454545454546\n",
            "F1 Score: 0.9333333333333332\n",
            "[[26  2]\n",
            " [ 1 21]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "#DataFrame 'df' with columns 'Review' and 'Sentiment'\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "predictions = model.predict(X_test_vectorized)\n",
        "\n",
        "y_test = [1 if label == \"positive\" else 0 for label in y_test]\n",
        "predictions = [1 if label == \"positive\" else 0 for label in predictions]\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, predictions))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, predictions))\n",
        "print(\"F1 Score:\", metrics.f1_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vexYzIP-en5a",
        "outputId": "c9e78a79-56fb-44fd-89ab-b71122497532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n",
            "Precision: 0.9\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9473684210526316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision tree classifier\n",
        "def decision_tree_classifier(train_x, train_y):\n",
        "  from sklearn import tree\n",
        "  model = tree.DecisionTreeClassifier()\n",
        "  model.fit(train_x, train_y)\n",
        "  return model\n",
        "\n",
        "  #KNN Classifier\n",
        "def knn_classifier(train_x, train_y):\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  model = KNeighborsClassifier()\n",
        "  model.fit(train_x,train_y)\n",
        "  return model\n",
        "\n",
        "  #Naive Bayes Classifier\n",
        "def naive_bayes_classifier(train_x, train_y):\n",
        "  from sklearn.naive_bayes import MultinomialNB\n",
        "  model = MultinomialNB(alpha = 0.01)\n",
        "  model.fit(train_x, train_y)\n",
        "  return model\n",
        "\n",
        "  #Logistic Regression Classifier\n",
        "def logistic_regression_classifier(train_x, train_y):\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  model = LogisticRegression(penalty = 'l2')\n",
        "  model.fit(train_x, train_y)\n",
        "  return model\n",
        "\n",
        "  #Gradient Boosting Classifier\n",
        "def Gradient_Boosting_Classifier(train_x, train_y):\n",
        "  from sklearn.ensemble import GradientBoostingClassifier\n",
        "  model = GradientBoostingClassifier()\n",
        "  model.fit(train_x, train_y)\n",
        "  return model\n",
        "\n",
        "  #SVM Classifier\n",
        "def svm_classifier(train_x, train_y):\n",
        "  from sklearn.svm import SVC\n",
        "  model = SVC(kernel = 'rbf', probability= True)\n",
        "  model.fit(train_x, train_y)\n",
        "  return model\n",
        "\n",
        "  # Random Forest Classifier\n",
        "def random_forest_classifier(train_x, train_y):\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  model = RandomForestClassifier(n_estimators= 100)\n",
        "  model.fit(train_x, train_y)\n",
        "  return model\n",
        "\n",
        "test_classifiers = [\n",
        "    'KNN',\n",
        "    'DT',\n",
        "    'NB',\n",
        "    'LR',\n",
        "    'RF',\n",
        "    'SVM',\n",
        "    'GBDT'\n",
        "]\n",
        "classifiers = {\n",
        "    'KNN':knn_classifier,\n",
        "    'DT':decision_tree_classifier,\n",
        "    'NB':naive_bayes_classifier,\n",
        "    'LR':logistic_regression_classifier,\n",
        "    'RF':random_forest_classifier,\n",
        "    'SVM':svm_classifier,\n",
        "    'GBDT':Gradient_Boosting_Classifier\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "3MdkD62Ihwts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for classifier in test_classifiers:\n",
        "  print('***************** %s *************' % classifier)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "  vectorizer = TfidfVectorizer(stop_words='english')\n",
        "  X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "  X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "  model = RandomForestClassifier()\n",
        "  model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "  predictions = model.predict(X_test_vectorized)\n",
        "\n",
        "  y_test = [1 if label == \"positive\" else 0 for label in y_test]\n",
        "  predictions = [1 if label == \"positive\" else 0 for label in predictions]\n",
        "\n",
        "\n",
        "  print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
        "  print(\"Precision:\", metrics.precision_score(y_test, predictions))\n",
        "  print(\"Recall:\", metrics.recall_score(y_test, predictions))\n",
        "  print(\"F1 Score:\", metrics.f1_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYnPK7ZhiX_U",
        "outputId": "97a052bf-e027-4917-9e84-fe4a38ad9f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***************** KNN *************\n",
            "Accuracy: 0.42857142857142855\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "***************** DT *************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.42857142857142855\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "***************** NB *************\n",
            "Accuracy: 0.5714285714285714\n",
            "Precision: 1.0\n",
            "Recall: 0.25\n",
            "F1 Score: 0.4\n",
            "***************** LR *************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.42857142857142855\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "***************** RF *************\n",
            "Accuracy: 0.42857142857142855\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "***************** SVM *************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5714285714285714\n",
            "Precision: 1.0\n",
            "Recall: 0.25\n",
            "F1 Score: 0.4\n",
            "***************** GBDT *************\n",
            "Accuracy: 0.42857142857142855\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "#DataFrame 'df' with columns 'Review' and 'Sentiment'\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Review'], df['Sentiment'], test_size=0.4, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "predictions = model.predict(X_test_vectorized)\n",
        "\n",
        "#Converts 'y' variable to 1's and 0's\n",
        "y_test = [1 if label == \"positive\" else 0 for label in y_test]\n",
        "predictions = [1 if label == \"positive\" else 0 for label in predictions]\n",
        "\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
        "print(\"Precision:\", metrics.precision_score(y_test, predictions))\n",
        "print(\"Recall:\", metrics.recall_score(y_test, predictions))\n",
        "print(\"F1 Score:\", metrics.f1_score(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhvi8iGtjSOu",
        "outputId": "f28a1f05-b3c9-49ae-8ade-a890674f13df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8\n",
            "Precision: 0.7\n",
            "Recall: 0.875\n",
            "F1 Score: 0.7777777777777777\n"
          ]
        }
      ]
    }
  ]
}